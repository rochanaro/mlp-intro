{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DS Bootcamp 2024 - MLP - Laboratory Session"
      ],
      "metadata": {
        "id": "5aZQKgPYzptd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Outline**\n",
        "1.   Training an MLP uysing TensorFlow & Keras\n",
        "    - configuring the python environment\n",
        "    - About the dataset\n",
        "        - MNIST\n",
        "        - FashinMNIST\n",
        "    - Preapre the dataset\n",
        "    - Hyper-Parameters\n",
        "        - epochs\n",
        "        - batch size\n",
        "        - learning rate\n",
        "    - Define the model\n",
        "    - Train the model\n",
        "    - Evaluate the model\n",
        "        - Expected results\n",
        "            - lower loss\n",
        "            - higher accuracy\n",
        "        - How to intepret results\n",
        "\n",
        "2. Additional Resources\n",
        "    - Training an MLP with PyTorch\n",
        "    - Why GPUs are required ?\n",
        "    - Platforms that you can use for deep learning\n",
        "        - Google Colab\n",
        "        - ODU Wahab Cluster\n",
        "        - Dedictaed GPU env at your own lab\n",
        "        - Your local machine with GPU capabiities\n",
        "    - Designing an MLP without deep learning frameworks such as TensorFlow, Keras, PyTorch\n",
        "\n",
        "<br><br>\n",
        "\n",
        "---\n",
        "\n",
        "__Rochana R. Obadage__<br>\n",
        "_15th April 2024_"
      ],
      "metadata": {
        "id": "8dl2fAKZXne8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/rochanaro/mlp-intro.git"
      ],
      "metadata": {
        "id": "J8a1T7AzpZ-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # optional\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Xca4gCp3qMWS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Training an MLP"
      ],
      "metadata": {
        "id": "KK0HRSE2pUt1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1. Configuring the python environment"
      ],
      "metadata": {
        "id": "IqFGQX64p_5-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_iYcla4kCX67"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kgna3kY6CX67",
        "outputId": "82c94d29-6c81-4b52-912b-7c50506601a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2. About the dataset\n",
        "\n",
        "- https://en.wikipedia.org/wiki/MNIST_database\n",
        "- http://yann.lecun.com/exdb/mnist/"
      ],
      "metadata": {
        "id": "GrNAczrPqX6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3. Preapre the dataset"
      ],
      "metadata": {
        "id": "3b9X00Hgu0u8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "JodgHy9nCX68",
        "outputId": "9e1a1e71-eec4-4081-836a-8669321da810"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data() # Load MNIST\n",
        "assert X_train.shape == (60000, 28, 28)\n",
        "assert X_test.shape == (10000, 28, 28)\n",
        "assert y_train.shape == (60000,)\n",
        "assert y_test.shape == (10000,)\n",
        "\n",
        "\n",
        "# Display randomly selected data\n",
        "indices = list(np.random.randint(X_train.shape[0],size=3))\n",
        "for i in range(3):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    plt.imshow(X_train[indices[i]].reshape(28,28), cmap='gray', interpolation='none')\n",
        "    plt.title(\"Index {} Class {}\".format(indices[i], y_train[indices[i]]))\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Important**\n",
        "* Always have a validation set, the procedure to create validation or dev set is by performing random sample without replacement on train set and then only using that fraction as dev set.\n",
        "* Simple approach is to set some K samples, you can extract them from start, mid or end.\n",
        "* Imagine validation set that partially approximates test set distribution and we assume our model would produce identical results when we test it on test set.\n",
        "* Always optimize your hyperparameters by looking at performance on validation set and not test set.\n",
        "* Do not touch test set, we have this to test how our model would work on unseen data."
      ],
      "metadata": {
        "id": "PowjAHuw-wm7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIRI-uLoCX69",
        "outputId": "6c43ee89-2edc-452e-8298-c716a94f32b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of training set is 50000 samples\n",
            "every train example is 28 by 28\n",
            "size of validation set is 10000 samples\n",
            "every validation example is 28 by 28\n",
            "size of training set is 50000 samples\n",
            "every train example has 784 features\n",
            "size of validation set is 10000 samples\n",
            "every validation example has 784 features\n"
          ]
        }
      ],
      "source": [
        "# Split train dataset into train and validation\n",
        "X_val = X_train[50000:60000]\n",
        "X_train = X_train[0:50000]\n",
        "y_val = y_train[50000:60000]\n",
        "y_train = y_train[0:50000]\n",
        "\n",
        "print(\"size of training set is\", str(X_train.shape[0]), \"samples\")\n",
        "print(\"every train example is\", str(X_train.shape[1]), \"by\", str(X_train.shape[2]))\n",
        "\n",
        "print(\"size of validation set is\", str(X_val.shape[0]), \"samples\")\n",
        "print(\"every validation example is\", str(X_val.shape[1]), \"by\", str(X_val.shape[2]))\n",
        "\n",
        "X_train = X_train.reshape(50000, 28*28)\n",
        "X_val = X_val.reshape(10000, 28*28)\n",
        "X_test = X_test.reshape(10000, 28*28)\n",
        "\n",
        "print(\"size of training set is\", str(X_train.shape[0]), \"samples\")\n",
        "print(\"every train example has\", str(X_train.shape[1]), \"features\")\n",
        "\n",
        "print(\"size of validation set is\", str(X_val.shape[0]), \"samples\")\n",
        "print(\"every validation example has\", str(X_val.shape[1]), \"features\")\n",
        "\n",
        "# Split dataset into batches\n",
        "#train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(16)\n",
        "#test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Points to remember**\n",
        "* If using any type of neural network, normalize your input between 0-1.\n",
        "* One can use various procedures to achieve this, divide by largest value (for images we use 255), subtract mean from data and then normalize, one can even augment them and use other steps for normalization.\n",
        "* Normalization is important step, one could observe significant boost in performance just by having better normalization scheme.\n",
        "* For targets we always use one-hot encodings."
      ],
      "metadata": {
        "id": "VdMEIaFKAscU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDyZ8bZjCX69",
        "outputId": "ceb07d3d-8c9a-4299-a840-7a211db998cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#Normalize Data\n",
        "\n",
        "X_train = X_train/255\n",
        "X_val = X_val/255\n",
        "X_test = X_test/255\n",
        "# X_train[0]\n",
        "np.max(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lIIy313CX69",
        "outputId": "cc09de24-92c8-4422-d50f-efa164d420f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([10000    10], shape=(2,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "size_input = X_train.shape[1] # 28*28 = 784\n",
        "size_hidden1 = 128\n",
        "size_hidden2 = 128\n",
        "size_hidden3 = 128\n",
        "size_output = 10 # number of classes\n",
        "\n",
        "number_of_train_examples = X_train.shape[0]\n",
        "number_of_test_examples = X_test.shape[0]\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10) # Other function is tf.one_hot(y_train,depth=10)\n",
        "y_val = tf.keras.utils.to_categorical(y_val, num_classes=10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
        "print(tf.shape(y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4. Hyper-Parameters\n",
        "\n",
        "- **Hyperparameters**: Hyperparameters are settings that you choose before training your model. They control aspects like learning rate, batch size, and more. Think of them as the settings on your cooking stove. You adjust them before cooking (training) to get the desired result.\n",
        "\n",
        "- **Epochs**: Epochs are like repetitions. They represent the number of times your model goes through the entire dataset during training. It's akin to reading the same book multiple times to grasp its content better.\n",
        "\n",
        "- **Batch Size**: Batch size refers to the number of examples the model sees at once during training. It's like how many pages you read at a time from the book. Smaller batch sizes are like reading a few pages at once, while larger batch sizes are like reading entire chapters at a time.\n",
        "\n",
        "- **Learning Rate**: Learning rate determines how much the model learns from each batch of data. It's like adjusting the size of steps you take while learning to dance. A higher learning rate means bigger steps, while a lower learning rate means smaller steps."
      ],
      "metadata": {
        "id": "mPVBoWIAwzvE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5. Define the model"
      ],
      "metadata": {
        "id": "lHpp0kQ5xVaU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Importance of weight initialization**\n",
        "\n",
        "* One reason backprop based models can perform bettter lies with the weight initialization method, one important point one should remember is that, if yur weights are initialized to be too high or low, backprop would struggle.\n",
        "* Hence one should always carefully initialize weights of your model, below i have shown approach with random_normal, one can use random_uniform, truncated version of both, Xavier init and orthogonal.\n",
        "* You will find modern day NNs have achieved stable and better performance by simply switching to better init and majority of cases Xavier or Orthogonal works best.\n",
        "* Always initialize your bias using zero or some small constant (ideally 0.01 or less works better). We use bias to shift the activation and in some cases it can stabalize learning, but having large bias can cause negative results."
      ],
      "metadata": {
        "id": "U7KCVarVCVPW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Loss function**\n",
        "\n",
        "* We will always use cross-entropy loss for classification.\n",
        "\n",
        "* tf softmax,\n",
        "loss= tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred_tf, labels=y_true_tf)), this function is simply saying that it will calculate softmax for you, simply provide logits to it.\n",
        "\n",
        "* In other output of your forward pass directly goes this function. Now this operator will calculate or apply softmax over prediction or logits and calculate cross-entropy between prediction and target. I am using reduce_mean since we apply this over batches.\n",
        "* Second is using keras\n",
        "Method 1 :- This function requires logits, hence same as above you will pass logits or output variable to this function. Now remember you need from_logits = True, for this to work.\n",
        "cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "loss_x = cce(y_true_tf, y_pred_tf)\n",
        "\n",
        "* Method 2:- In this we will apply softmax to output function and then pass to CCE loss.\n",
        "So the approach is\n",
        "output = tf.nn.softmax(output)\n",
        "cce = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
        "loss_x = cce(y_true_tf, y_pred_tf)"
      ],
      "metadata": {
        "id": "CvxizMD5xSG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(object):\n",
        "    def __init__(self, size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device=None):\n",
        "        \"\"\"\n",
        "        size_input: int, size of input layer\n",
        "        size_hidden1: int, size of the 1st hidden layer\n",
        "        size_hidden2: int, size of the 2nd hidden layer\n",
        "        size_hidden3: int, size of the 3rd hidden layer\n",
        "        size_output: int, size of output layer\n",
        "        device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "        \"\"\"\n",
        "        self.size_input, self.size_hidden1, self.size_hidden2, self.size_hidden3, self.size_output, self.device =\\\n",
        "        size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device\n",
        "\n",
        "        # Initialize weights between input mapping and a layer g(f(x)) = layer\n",
        "        self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden1], stddev=0.1))  # Xavier(Fan-in fan-out) and Orthogonal\n",
        "        # Initialize biases for hidden layer\n",
        "        self.b1 = tf.Variable(tf.zeros([1, self.size_hidden1]))  # 0 or constant(0.01)\n",
        "\n",
        "        # Initialize weights between input layer and 1st hidden layer\n",
        "        self.W2 = tf.Variable(tf.random.normal([self.size_hidden1, self.size_hidden2], stddev=0.1))\n",
        "        # Initialize biases for hidden layer\n",
        "        self.b2 = tf.Variable(tf.zeros([1, self.size_hidden2]))\n",
        "\n",
        "        # Initialize weights between 1st hidden layer and 2nd hidden layer\n",
        "        self.W3 = tf.Variable(tf.random.normal([self.size_hidden2, self.size_hidden3], stddev=0.1))\n",
        "        # Initialize biases for hidden layer\n",
        "        self.b3 = tf.Variable(tf.zeros([1, self.size_hidden3]))\n",
        "\n",
        "        # Initialize weights between 2nd hidden layer and output layer\n",
        "        self.W4 = tf.Variable(tf.random.normal([self.size_hidden3, self.size_output], stddev=0.1))\n",
        "        # Initialize biases for output layer\n",
        "        self.b4 = tf.Variable(tf.zeros([1, self.size_output]))\n",
        "\n",
        "        # Define variables to be updated during backpropagation\n",
        "        self.variables = [self.W1, self.W2, self.W3, self.W4, self.b1, self.b2, self.b3, self.b4]\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        forward pass\n",
        "        X: Tensor, inputs\n",
        "        \"\"\"\n",
        "        if self.device is not None:\n",
        "            with tf.device('GPU:0' if self.device == 'gpu' else 'cpu'):\n",
        "                self.y = self.compute_output(X)\n",
        "        else:\n",
        "            self.y = self.compute_output(X)\n",
        "\n",
        "        return self.y\n",
        "\n",
        "    def loss(self, y_pred, y_true):\n",
        "        '''\n",
        "        y_pred - Tensor of shape (batch_size, size_output)\n",
        "        y_true - Tensor of shape (batch_size, size_output)\n",
        "        '''\n",
        "        y_true_tf = tf.cast(y_true, dtype=tf.float32)\n",
        "        y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "        cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "        loss_x = cce(y_true_tf, y_pred_tf)\n",
        "\n",
        "        return loss_x\n",
        "\n",
        "    def backward(self, X_train, y_train):\n",
        "        \"\"\"\n",
        "        backward pass\n",
        "        \"\"\"\n",
        "        optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "\n",
        "            predicted = self.forward(X_train)\n",
        "            current_loss = self.loss(predicted, y_train)\n",
        "\n",
        "        grads = tape.gradient(current_loss, self.variables)\n",
        "        optimizer.apply_gradients(zip(grads, self.variables))\n",
        "\n",
        "    @tf.function\n",
        "    def compute_output(self, X):\n",
        "        \"\"\"\n",
        "        Custom method to obtain output tensor during forward pass\n",
        "        \"\"\"\n",
        "        # Cast X to float32\n",
        "        X_tf = tf.cast(X, dtype=tf.float32)\n",
        "\n",
        "        # Compute values in hidden layers\n",
        "        z1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "        h1 = tf.nn.relu(z1)\n",
        "\n",
        "        z2 = tf.matmul(h1, self.W2) + self.b2\n",
        "        h2 = tf.nn.relu(z2)\n",
        "\n",
        "        z3 = tf.matmul(h2, self.W3) + self.b3\n",
        "        h3 = tf.nn.relu(z3)\n",
        "\n",
        "        # Compute output\n",
        "        output = tf.matmul(h3, self.W4) + self.b4\n",
        "\n",
        "        return output\n",
        "\n",
        "#  def stderr(self,y_pred):\n",
        "#     \"\"\"\n",
        "#      Calculate standard error\n",
        "#      \"\"\"\n",
        "#     y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "#     std_dev = np.std(y_pred_tf) #Calculates standard deviation\n",
        "#     std_err = std_dev/sqrt(len(y_pred_tf))\n",
        "#     return std_err\n",
        "\n",
        "\n",
        "#  def var(self,y_pred):\n",
        "#     \"\"\"\n",
        "#      Calculate variance\n",
        "#      \"\"\"\n",
        "#     y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "#     std_dev = np.std(y_pred_tf) #Calculates standard deviation\n",
        "#     variance = (std_dev**2) # calculate variance\n",
        "#     return variance"
      ],
      "metadata": {
        "id": "gUOZNTHzGARF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.6. Train the model"
      ],
      "metadata": {
        "id": "OzEKP59Lxrnx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "id": "pOnhvVlUCX6-",
        "outputId": "1b75651a-a3ed-4343-f39b-3f2d670b7a24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7c57431c9480> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7c57431c9480> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of Epochs: 1\n",
            "Average Cross Entropy Loss: 0.0037817868041992186 \n",
            "Train Accuracy: 0.9152\n",
            "\n",
            "Validation Accuracy: 0.9218\n",
            "\n",
            "\n",
            "Number of Epochs: 2\n",
            "Average Cross Entropy Loss: 0.0016913644409179687 \n",
            "Train Accuracy: 0.9368\n",
            "\n",
            "Validation Accuracy: 0.9425\n",
            "\n",
            "\n",
            "Total time taken (in seconds): 283.07\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Set number of epochs\n",
        "NUM_EPOCHS = 2 #10 #20\n",
        "\n",
        "# Initialize model using CPU\n",
        "mlp_on_cpu = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(1234)).batch(128) #32 or 64 or 128\n",
        "  kz = 0\n",
        "  accuracy_z = 0.0\n",
        "  cur_train_acc = 0.0\n",
        "  for inputs, outputs in train_ds:\n",
        "    qw, tr = tf.shape(inputs)\n",
        "    kz = kz + 1\n",
        "    preds = mlp_on_cpu.forward(inputs)\n",
        "    loss_total = loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
        "    mlp_on_cpu.backward(inputs, outputs)\n",
        "\n",
        "  preds = mlp_on_cpu.forward(X_train)\n",
        "  # Get probs, remember we only have logits from our forward function, we need to apply softmax on top of it to get probs\n",
        "  preds = tf.nn.softmax(preds)\n",
        "  correct_prediction = tf.equal(tf.argmax(preds, 1), tf.argmax(y_train, 1))\n",
        "  accuracy_z = accuracy_z + tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  cur_train_acc += accuracy_z.numpy()\n",
        "  ds = cur_train_acc\n",
        "\n",
        "  print('\\nNumber of Epochs: {}'.format(epoch + 1))\n",
        "  print('Average Cross Entropy Loss: {} '.format(np.sum(loss_total) / X_train.shape[0]))\n",
        "  print('Train Accuracy: {:.4f}\\n'.format(ds))\n",
        "\n",
        "  preds_val = mlp_on_cpu.forward(X_val)\n",
        "  preds_val = tf.nn.softmax(preds_val)\n",
        "  correct_prediction = tf.equal(tf.argmax(preds_val, 1), tf.argmax(y_val, 1))\n",
        "\n",
        "  # Calculate accuracy\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  cur_val_acc = accuracy.numpy()\n",
        "\n",
        "  print('Validation Accuracy: {:.4f}\\n'.format(cur_val_acc))\n",
        "\n",
        "  plt.plot(epoch + 1, np.sum(loss_total) / X_train.shape[0], 'go')\n",
        "\n",
        "\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "# Validate model\n",
        "\n",
        "\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.7. Evaluate the model"
      ],
      "metadata": {
        "id": "OwjG_hjpyHLD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8eNKeELWCX6_",
        "outputId": "185f08d3-0a44-486a-e90e-d193ec092358",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.0518\n",
            "\n",
            "Test Accuracy: 0.93\n"
          ]
        }
      ],
      "source": [
        "# Initialize\n",
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "correct_prediction = tf.Variable(0, dtype=tf.float32)\n",
        "\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(4)\n",
        "\n",
        "\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_cpu.forward(inputs)\n",
        "  test_loss_total = test_loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "print('Test loss: {:.4f}'.format(np.sum(test_loss_total.numpy()) / X_test.shape[0]))\n",
        "\n",
        "# Test model\n",
        "preds_test = mlp_on_cpu.forward(X_test)\n",
        "preds_test = tf.nn.softmax(preds_test)\n",
        "correct_prediction = tf.equal(tf.argmax(preds_test, 1), tf.argmax(y_test, 1))\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "cur_test_acc = accuracy.numpy()\n",
        "print('\\nTest Accuracy: {:.2f}'.format(cur_test_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Additional Resources"
      ],
      "metadata": {
        "id": "QyaLG6tKyXJc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1. Training an MLP with PyTorch\n",
        "- **Ref_Multilayer_Perceptron_PyTorch.ipynb**\n",
        "    - https://github.com/rochanaro/mlp-intro/blob/main/Ref_Multilayer_Perceptron_PyTorch.ipynb\n",
        "- Referenced from:\n",
        "    - https://colab.research.google.com/github/bentrevett/pytorch-image-classification/blob/master/1_mlp.ipynb"
      ],
      "metadata": {
        "id": "iie6WE8i0Dm4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2. Why GPUs are required ?\n",
        "- https://telnyx.com/resources/gpu-architecture-ai\n",
        "- https://www.youtube.com/watch?v=jP_KOQnl6yo\n"
      ],
      "metadata": {
        "id": "TLh05PrZ0Dp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3. Platforms that you can use for deep learning\n",
        "- Google Colab\n",
        "    - https://colab.research.google.com/\n",
        "- ODU Wahab Cluster\n",
        "    - https://wiki.hpc.odu.edu/en/GettingStarted\n",
        "- Dedictaed GPU env at your own lab\n",
        "- Your local machine with GPU capabiities\n",
        "    - **Windows**:\n",
        "        - NVIDIA GPU: CUDA Compute Capability 3.0 or higher\n",
        "        - Memory: At least 8GB RAM (preferably 16GB or more)\n",
        "        - Processor: Intel Core i5 or higher (or AMD Ryzen equivalent)\n",
        "    - **MacOS**:\n",
        "        - Apple M1 Chip (or newer)\n",
        "        - RAM: At least 8GB\n",
        "        - Storage: SSD storage\n",
        "        - Software Compatibility: Check compatibility with macOS for desired deep learning frameworks.\n",
        "    - **References**\n",
        "        - https://towardsdatascience.com/another-deep-learning-hardware-guide-73a4c35d3e86\n",
        "        - https://www.toolify.ai/ai-news/get-started-with-machine-learning-and-deep-learning-minimum-laptop-configuration-19506\n"
      ],
      "metadata": {
        "id": "UtAdxSAX0Dsy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4. Designing an MLP without deep learning frameworks such as TensorFlow, Keras, PyTorch\n",
        "- https://github.com/KirillShmilovich/MLP-Neural-Network-From-Scratch/blob/master/MLP.ipynb"
      ],
      "metadata": {
        "id": "0ZAfy6VM0Dva"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GcfWqLNhEar5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}